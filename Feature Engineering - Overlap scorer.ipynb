{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (default, Aug 13 2019, 20:35:49) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import re\n",
    "import sys\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "import string\n",
    "import random\n",
    "\n",
    "import fuzzy\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import codecs, difflib, Levenshtein, distance\n",
    "\n",
    "debugYesGlobal = False\n",
    "\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str1 = \"sachin kumar went for a ride and was tired\"\n",
    "str2 = \"sachin kumar came from a ride and felt tired \"\n",
    "\n",
    "str1 = str1.split()\n",
    "str2 = str2.split()\n",
    "matches = len(set(str1) & set(str2))\n",
    "overlap_score = matches/(len(set(str1)) + len(set(str2)) - matches)\n",
    "\n",
    "round(overlap_score,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Get Exact Overlap score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# NON-FUZZY OVERLAP SCORE. \n",
    "# Uses 'Set' to ignore duplicates. \n",
    "# Used for finding Exact match of 'PHOENETIC ENCODING'\n",
    "# NOTE : It is case sensitive\n",
    "\n",
    "def getExactOverlap (str1, str2) : \n",
    "    str1 = str1.split()\n",
    "    str2 = str2.split()\n",
    "    matches = len(set(str1) & set(str2))\n",
    "    overlap_score = matches / (len(set(str1)) + len(set(str2)) - matches)\n",
    "    return round(overlap_score, 2)\n",
    "    \n",
    "# Watch case        \n",
    "print (getExactOverlap ('Hello world hello', 'Hello world'))\n",
    "print (getExactOverlap ('Hello world Hello', 'Hello world'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various edit distances from variety of algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difflib: 0.64 | Levenshtein: 0.64 | sorensen: 0.8 | jaccard 0.67 | exact 0.0\n",
      "difflib: 1.0 | Levenshtein: 1.0 | sorensen: 1.0 | jaccard 1.0 | exact 1.0\n"
     ]
    }
   ],
   "source": [
    "def getEditDistanceManyAlgos(sr3, sr4):\n",
    "    diffl   = difflib.SequenceMatcher(None, sr3, sr4).ratio()\n",
    "    lev     = Levenshtein.ratio(sr3, sr4) \n",
    "    sor     = 1 - distance.sorensen(sr3, sr4)\n",
    "    jac     = 1 - distance.jaccard(sr3, sr4)\n",
    "    exact   = getExactOverlap (sr3, sr4)\n",
    "    print (\"difflib:\", round(diffl,2), \"| Levenshtein:\", round(lev,2), \"| sorensen:\", round(sor,2), \"| jaccard\", round(jac,2), \"| exact\", round(exact,2))\n",
    "\n",
    "getEditDistanceManyAlgos ('Cukharlotte', 'edda Charlorte')\n",
    "getEditDistanceManyAlgos ('Cukharlotte', 'Cukharlotte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33\n",
      "0.33\n",
      "0.33\n"
     ]
    }
   ],
   "source": [
    "def getEditDistance (str1, str2, type) :\n",
    "    score = 0\n",
    "    if int(type) == 1 : score =  difflib.SequenceMatcher(None, str1, str2).ratio()\n",
    "    if int(type) == 2 : score =  Levenshtein.ratio(str1, str2)\n",
    "    if int(type) == 3 : score =  (1 - distance.sorensen(str1, str2))\n",
    "    if int(type) == 4 : score =  (1 - distance.jaccard(str1, str2))\n",
    "    if int(type) == 5 : score =  getExactOverlap (str1, str2)\n",
    "    return round(score,2)\n",
    "\n",
    "print (getEditDistance(\"Nike india\",\"Nike USA\", 5))\n",
    "print (getEditDistance(\"india Nike\",\"Nike India\", 5))\n",
    "print (getEditDistance(\"india Nikx\",\"india Nike\", 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difflib: 0.75 | Levenshtein: 0.75 | sorensen: 0.75 | jaccard 0.6 | exact 0.0\n"
     ]
    }
   ],
   "source": [
    "getEditDistanceManyAlgos('nike', 'nikx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R163\n",
      "R163\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/Lilykos/pyphonetics\n",
    "from pyphonetics import Soundex\n",
    "soundex = Soundex()\n",
    "print(soundex.phonetics('Rupert'))\n",
    "#'R163'\n",
    "print(soundex.phonetics('Robert'))\n",
    "#'R163'\n",
    "print(soundex.sounds_like('Robert', 'Rupert'))\n",
    "#True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSKRMNXN\n"
     ]
    }
   ],
   "source": [
    "from pyphonetics import Metaphone\n",
    "metaphone = Metaphone()\n",
    "print(metaphone.phonetics('discrimination'))\n",
    "#'TSKRMNXN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Metaphone: [b'FS', None]\n",
      "nysiis: FASY\n",
      "Soundex: F200\n"
     ]
    }
   ],
   "source": [
    "import fuzzy\n",
    "dmeta = fuzzy.DMetaphone()\n",
    "print (\"Double Metaphone:\", dmeta('fuzzy'))\n",
    "#['FS', None]\n",
    "\n",
    "print (\"nysiis:\", fuzzy.nysiis('fuzzy'))\n",
    "#'FASY'\n",
    "\n",
    "\n",
    "soundex = fuzzy.Soundex(4)\n",
    "print (\"Soundex:\", soundex('fuzzy'))\n",
    "#'F200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86\n"
     ]
    }
   ],
   "source": [
    "# Simple Metaphone\n",
    "def getPhoeneticDistanceMeta (str1, str2) :\n",
    "    # Get the proper nouns as a string\n",
    "    \n",
    "    str1 = str1.split()\n",
    "    str2 = str2.split()\n",
    " \n",
    "    \n",
    "    str1_meta = ' '.join([metaphone.phonetics(item) for item in str1])\n",
    "    str2_meta = ' '.join([metaphone.phonetics(item) for item in str2])\n",
    "\n",
    "    score =  getExactOverlap (str1_meta, str2_meta)\n",
    "    \n",
    "    if debugYesGlobal : \n",
    "        print (\"\\n\")\n",
    "        print (\"1:\", ' '.join(str1), \"| 2:\", ' '.join(str2))\n",
    "        print (\"1:\", str1_meta, \"| 2:\", str2_meta)        \n",
    "    \n",
    "    return round(score,2)\n",
    "\n",
    "# Testing\n",
    "print(getPhoeneticDistanceMeta('Michael likes to eat at McDonalds',' Jackson likes to eat at McDonalds Michael'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38\n"
     ]
    }
   ],
   "source": [
    "# Here 'Exact Match' and 'Soundex' are considered in sequence \n",
    "# (NOTE: 'Exact Match' just improves performance. 'Soundex' alone can handle exact match.)\n",
    "def getPhoeneticDistanceSoundex (str1, str2) :\n",
    "    # Get the proper nouns as a string\n",
    "    \n",
    "    # Lowercase\n",
    "    str1 = str1.lower()\n",
    "    str2 = str2.lower()    \n",
    "    \n",
    "    str1 = str1.split()\n",
    "    str2 = str2.split()\n",
    "    initial_count_both_strings = len(str1) + len(str2)\n",
    "    if debugYesGlobal: print (\"BEFORE REMOVING COMMON >>>>1:\", ' '.join(str1), \"| 2:\", ' '.join(str2))\n",
    "    \n",
    "    # Exact match count, in case-insensitive way\n",
    "    matches_exact = len(set(str1) & set(str2))\n",
    "    if debugYesGlobal: print (\"Exact Matches (case?) : \", matches_exact)\n",
    "    \n",
    "    #removing exact matches\n",
    "    for i in str1[:]:\n",
    "      if i in str2:\n",
    "          str1.remove(i)\n",
    "          str2.remove(i)\n",
    "\n",
    "    if debugYesGlobal: print (\"AFTER REMOVING COMMON >>>>1:\", ' '.join(str1), \"| 2:\", ' '.join(str2))\n",
    "    \n",
    "    \n",
    "    str1_Soundex_list = []\n",
    "    for item in str1 :\n",
    "        L = [soundex(item)]\n",
    "        #L = list(filter(None.__ne__, L))\n",
    "        #if len(L) == 2 : str1Bloat += 1\n",
    "        str1_Soundex_list = str1_Soundex_list + L\n",
    "    #print (\"str1Bloat=\", str1Bloat) \n",
    "    \n",
    "    str2_Soundex_list = []\n",
    "    for item in str2 :\n",
    "        L = [soundex(item)]\n",
    "        #L = list(filter(None.__ne__, L))\n",
    "        #if len(L) == 2 : str2Bloat += 1\n",
    "        str2_Soundex_list = str2_Soundex_list + L\n",
    "    #print (\"str2Bloat=\", str2Bloat)\n",
    "    \n",
    "    matches_Soundex = 0\n",
    "    items_covered1 = []\n",
    "    # Find common matches based on Soundex\n",
    "    for item in str1 :\n",
    "        L = [soundex(item)]\n",
    "        #L = list(filter(None.__ne__, L))\n",
    "        \n",
    "        # Exact match count, using Soundex codes\n",
    "        if (len(set(str2_Soundex_list) & set(L))) > 0 : \n",
    "            matches_Soundex += 1 \n",
    "            items_covered1.append(item)\n",
    "    if debugYesGlobal: print (\"Exact Soundex Matches (case?) : \", matches_Soundex)\n",
    "    \n",
    "    items_covered2 = []\n",
    "    for item in str2 :\n",
    "        L = [soundex(item)]\n",
    "        #L = list(filter(None.__ne__, L))\n",
    "        \n",
    "        # Exact match count, using Soundex codes\n",
    "        if (len(set(str1_Soundex_list) & set(L))) > 0 : \n",
    "            #matches_Soundex += 1 \n",
    "            items_covered2.append(item)    \n",
    "    \n",
    "    if debugYesGlobal: \n",
    "        print (\"Soundex items_covered1 : \", items_covered1)\n",
    "        print (\"Soundex items_covered2 : \", items_covered2)\n",
    "    \n",
    "    #Remove items covered from both strings\n",
    "    if debugYesGlobal: print (\"BEFORE REMOVING COMMON (Soundex) >>>>1:\", ' '.join(str1), \"| 2:\", ' '.join(str2))\n",
    "    #removing ones matched with Soundex\n",
    "    for i in str1[:]:\n",
    "          if i in items_covered1:\n",
    "                  str1.remove(i)\n",
    "        \n",
    "    for i in str2[:]:\n",
    "          if i in items_covered2:\n",
    "                  str2.remove(i)\n",
    "    \n",
    "    if debugYesGlobal: print (\"AFTER REMOVING COMMON (Soundex) >>>>1:\", ' '.join(str1), \"| 2:\", ' '.join(str2))\n",
    "        \n",
    "    total_matches = matches_exact + matches_Soundex\n",
    "    score = total_matches / (initial_count_both_strings - total_matches)\n",
    "       \n",
    "    \n",
    "    return round(score,2)\n",
    "\n",
    "\n",
    "#print(getPhoeneticDistanceSoundex('Michael likes to eat at McDonalds',' Jackson likes to eat at McDonalds Michael'))\n",
    "#print(getPhoeneticDistanceSoundex('Michael likes to eat at McDonalds',' Jackson likes to eat at McDonalds Michael'))\n",
    "\n",
    "print(getPhoeneticDistanceSoundex('Schmidt Ripan Jackson McDonalds sauchages bun',' Smith Jackson Rupam McDonalds omlet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38\n"
     ]
    }
   ],
   "source": [
    "# Here 'Exact Match' and 'nysiis' are considered in sequence \n",
    "# (NOTE: 'Exact Match' just improves performance. 'nysiis' alone can handle exact match.)\n",
    "def getPhoeneticDistanceNysiis (str1, str2) :\n",
    "    # Get the proper nouns as a string\n",
    "    \n",
    "    # Lowercase\n",
    "    str1 = str1.lower()\n",
    "    str2 = str2.lower()    \n",
    "    \n",
    "    str1 = str1.split()\n",
    "    str2 = str2.split()\n",
    "    initial_count_both_strings = len(str1) + len(str2)\n",
    "    if debugYesGlobal: print (\"BEFORE REMOVING COMMON >>>>1:\", ' '.join(str1), \"| 2:\", ' '.join(str2))\n",
    "    \n",
    "    # Exact match count, in case-insensitive way\n",
    "    matches_exact = len(set(str1) & set(str2))\n",
    "    if debugYesGlobal: print (\"Exact Matches (case?) : \", matches_exact)\n",
    "    \n",
    "    #removing exact matches\n",
    "    for i in str1[:]:\n",
    "      if i in str2:\n",
    "          str1.remove(i)\n",
    "          str2.remove(i)\n",
    "\n",
    "    if debugYesGlobal: print (\"AFTER REMOVING COMMON >>>>1:\", ' '.join(str1), \"| 2:\", ' '.join(str2))\n",
    "    \n",
    "    \n",
    "    str1_nysiis_list = []\n",
    "    for item in str1 :\n",
    "        L = [fuzzy.nysiis(item)]\n",
    "        #L = list(filter(None.__ne__, L))\n",
    "        #if len(L) == 2 : str1Bloat += 1\n",
    "        str1_nysiis_list = str1_nysiis_list + L\n",
    "    #print (\"str1Bloat=\", str1Bloat) \n",
    "    \n",
    "    str2_nysiis_list = []\n",
    "    for item in str2 :\n",
    "        L = [fuzzy.nysiis(item)]\n",
    "        #L = list(filter(None.__ne__, L))\n",
    "        #if len(L) == 2 : str2Bloat += 1\n",
    "        str2_nysiis_list = str2_nysiis_list + L\n",
    "    #print (\"str2Bloat=\", str2Bloat)\n",
    "    \n",
    "    matches_nysiis = 0\n",
    "    items_covered1 = []\n",
    "    # Find common matches based on nysiis\n",
    "    for item in str1 :\n",
    "        L = [fuzzy.nysiis(item)]\n",
    "        #L = list(filter(None.__ne__, L))\n",
    "        \n",
    "        # Exact match count, using nysiis codes\n",
    "        if (len(set(str2_nysiis_list) & set(L))) > 0 : \n",
    "            matches_nysiis += 1 \n",
    "            items_covered1.append(item)\n",
    "    if debugYesGlobal: print (\"Exact nysiis Matches (case?) : \", matches_nysiis)\n",
    "    \n",
    "    items_covered2 = []\n",
    "    for item in str2 :\n",
    "        L = [fuzzy.nysiis(item)]\n",
    "        #L = list(filter(None.__ne__, L))\n",
    "        \n",
    "        # Exact match count, using nysiis codes\n",
    "        if (len(set(str1_nysiis_list) & set(L))) > 0 : \n",
    "            #matches_nysiis += 1 \n",
    "            items_covered2.append(item)    \n",
    "    \n",
    "    if debugYesGlobal: \n",
    "        print (\"nysiis items_covered1 : \", items_covered1)\n",
    "        print (\"nysiis items_covered2 : \", items_covered2)\n",
    "    \n",
    "    #Remove items covered from both strings\n",
    "    if debugYesGlobal: print (\"BEFORE REMOVING COMMON (nysiis) >>>>1:\", ' '.join(str1), \"| 2:\", ' '.join(str2))\n",
    "    #removing ones matched with nysiis\n",
    "    for i in str1[:]:\n",
    "      if i in items_covered1:\n",
    "          str1.remove(i)\n",
    "        \n",
    "    for i in str2[:]:\n",
    "      if i in items_covered2:\n",
    "          str2.remove(i)\n",
    "    if debugYesGlobal: print (\"AFTER REMOVING COMMON (nysiis) >>>>1:\", ' '.join(str1), \"| 2:\", ' '.join(str2))\n",
    "        \n",
    "    total_matches = matches_exact + matches_nysiis\n",
    "    score = total_matches / (initial_count_both_strings - total_matches)\n",
    "       \n",
    "    \n",
    "    return round(score,2)\n",
    "\n",
    "\n",
    "#print(getPhoeneticDistanceNysiis('Michael likes to eat at McDonalds',' Jackson likes to eat at McDonalds Michael'))\n",
    "#print(getPhoeneticDistanceNysiis('Michael likes to eat at McDonalds',' Jackson likes to eat at McDonalds Michael'))\n",
    "\n",
    "print(getPhoeneticDistanceNysiis('Schmidt Ripan Jackson McDonalds sauchages bun',' Smith Jackson Rupam McDonalds omlet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Here 'Exact Match' and 'Double Metaphone' are considered in sequence \n",
    "# (NOTE: 'Exact Match' just improves performance. 'Double Metaphone' alone can handle exact match.)\n",
    "def getPhoeneticDistanceDMeta2 (str1, str2) :\n",
    "    # Get the proper nouns as a string\n",
    "    \n",
    "    # Lowercase\n",
    "    str1 = str1.lower()\n",
    "    str2 = str2.lower()    \n",
    "    \n",
    "    str1 = str1.split()\n",
    "    str2 = str2.split()\n",
    "    initial_count_both_strings = len(str1) + len(str2)\n",
    "    if debugYesGlobal: print (\"BEFORE REMOVING COMMON >>>>1:\", ' '.join(str1), \"| 2:\", ' '.join(str2))\n",
    "    #str1_dmeta = ' '.join([' '.join(dmeta(item)) for item in str1])\n",
    "    #str2_dmeta = ' '.join([' '.join(dmeta(item)) for item in str2])\n",
    "    \n",
    "    # Exact match count, in case-insensitive way\n",
    "    matches_exact = len(set(str1) & set(str2))\n",
    "    if debugYesGlobal: print (\"Exact Matches (case?) : \", matches_exact)\n",
    "    \n",
    "    #removing exact matches\n",
    "    for i in str1[:]:\n",
    "      if i in str2:\n",
    "          str1.remove(i)\n",
    "          str2.remove(i)\n",
    "\n",
    "    if debugYesGlobal: print (\"AFTER REMOVING COMMON >>>>1:\", ' '.join(str1), \"| 2:\", ' '.join(str2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    str1_dmeta_list = []\n",
    "    for item in str1 :\n",
    "        L = dmeta(item)\n",
    "        L = list(filter(None.__ne__, L))\n",
    "        #if len(L) == 2 : str1Bloat += 1\n",
    "        str1_dmeta_list = str1_dmeta_list + L\n",
    "    #print (\"str1Bloat=\", str1Bloat) \n",
    "    \n",
    "    str2_dmeta_list = []\n",
    "    for item in str2 :\n",
    "        L = dmeta(item)\n",
    "        L = list(filter(None.__ne__, L))\n",
    "        #if len(L) == 2 : str2Bloat += 1\n",
    "        str2_dmeta_list = str2_dmeta_list + L\n",
    "    #print (\"str2Bloat=\", str2Bloat)\n",
    "    \n",
    "    matches_Dmeta = 0\n",
    "    items_covered1 = []\n",
    "    # Find common matches based on DMETAPHONE\n",
    "    for item in str1 :\n",
    "        L = dmeta(item)\n",
    "        L = list(filter(None.__ne__, L))\n",
    "        \n",
    "        # Exact match count, using DMeta codes\n",
    "        if (len(set(str2_dmeta_list) & set(L))) > 0 : \n",
    "            matches_Dmeta += 1 \n",
    "            items_covered1.append(item)\n",
    "    if debugYesGlobal: print (\"Exact DMeta Matches (case?) : \", matches_Dmeta)\n",
    "    \n",
    "    items_covered2 = []\n",
    "    for item in str2 :\n",
    "        L = dmeta(item)\n",
    "        L = list(filter(None.__ne__, L))\n",
    "        \n",
    "        # Exact match count, using DMeta codes\n",
    "        if (len(set(str1_dmeta_list) & set(L))) > 0 : \n",
    "            #matches_Dmeta += 1 \n",
    "            items_covered2.append(item)    \n",
    "    \n",
    "    if debugYesGlobal: \n",
    "        print (\"DMETA items_covered1 : \", items_covered1)\n",
    "        print (\"DMETA items_covered2 : \", items_covered2)\n",
    "    \n",
    "    #Remove items covered from both strings\n",
    "    if debugYesGlobal: print (\"BEFORE REMOVING COMMON (DMETA) >>>>1:\", ' '.join(str1), \"| 2:\", ' '.join(str2))\n",
    "    #removing ones matched with DMETA\n",
    "    for i in str1[:]:\n",
    "      if i in items_covered1:\n",
    "          str1.remove(i)\n",
    "        \n",
    "    for i in str2[:]:\n",
    "      if i in items_covered2:\n",
    "          str2.remove(i)\n",
    "    if debugYesGlobal: print (\"AFTER REMOVING COMMON (DMETA) >>>>1:\", ' '.join(str1), \"| 2:\", ' '.join(str2))\n",
    "        \n",
    "    total_matches = matches_exact + matches_Dmeta\n",
    "    score = total_matches / (initial_count_both_strings - total_matches)\n",
    "       \n",
    "    \n",
    "    return round(score,2)\n",
    "\n",
    "\n",
    "print(getPhoeneticDistanceDMeta2('Schmidt  Jackson McDonalds sauchages bun',' Smith Jackson McDonalds omlet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "#Clean text to extract words from raw data\n",
    "# Raw product description text are run through :\n",
    "#   a) Lowercasing all the letters \n",
    "#   b) remove punctuations, special characters, stopwords \n",
    "#   c) remove all numerical texts\n",
    "def getStopwordRemovedString(rawData):  \n",
    "    #res =  rawData.split(';')\n",
    "    res =  re.split(r'\\W+', rawData)\n",
    "    # Lowercase\n",
    "    res = ' '.join([word.lower() for word in res if (word.isalpha() and word not in stop_words)])\n",
    "    #res = ' '.join([word for word in res if (word.isalpha() and word not in stop_words)])\n",
    "    if debugYesGlobal: print (\">>>\", res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53\n"
     ]
    }
   ],
   "source": [
    "# Here 'Exact Match', 'Double Metaphone' and 'Levenshtein' are considered in sequence\n",
    "def getCombinedDistanceSequential (str1, str2) :\n",
    "    # Get the proper nouns as a string\n",
    "    \n",
    "    # Lowercase\n",
    "    #str1 = str1.lower()\n",
    "    #str2 = str2.lower()\n",
    "    \n",
    "    str1 = getStopwordRemovedString(str1)\n",
    "    str2 = getStopwordRemovedString(str2)\n",
    "    if debugYesGlobal:     \n",
    "        print (str1)\n",
    "        print (str2)    \n",
    "    \n",
    "    str1 = str1.split()\n",
    "    str2 = str2.split()\n",
    "    initial_count_both_strings = len(str1) + len(str2)\n",
    "    if debugYesGlobal: print (\"BEFORE REMOVING COMMON >>>>1:\", ' '.join(str1), \"| 2:\", ' '.join(str2))\n",
    "    #str1_dmeta = ' '.join([' '.join(dmeta(item)) for item in str1])\n",
    "    #str2_dmeta = ' '.join([' '.join(dmeta(item)) for item in str2])\n",
    "    \n",
    "    # Exact match count, in case-insensitive way\n",
    "    matches_exact = len(set(str1) & set(str2))\n",
    "    if debugYesGlobal: print (\"Exact Matches (case?) : \", matches_exact)\n",
    "    \n",
    "    #removing exact matches\n",
    "    for i in str1[:]:\n",
    "      if i in str2:\n",
    "          str1.remove(i)\n",
    "          str2.remove(i)\n",
    "\n",
    "    if debugYesGlobal: print (\"AFTER REMOVING COMMON >>>>1:\", ' '.join(str1), \"| 2:\", ' '.join(str2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    str1_dmeta_list = []\n",
    "    for item in str1 :\n",
    "        L = dmeta(item)\n",
    "        L = list(filter(None.__ne__, L))\n",
    "        #if len(L) == 2 : str1Bloat += 1\n",
    "        str1_dmeta_list = str1_dmeta_list + L\n",
    "    #print (\"str1Bloat=\", str1Bloat) \n",
    "    \n",
    "    str2_dmeta_list = []\n",
    "    for item in str2 :\n",
    "        L = dmeta(item)\n",
    "        L = list(filter(None.__ne__, L))\n",
    "        #if len(L) == 2 : str2Bloat += 1\n",
    "        str2_dmeta_list = str2_dmeta_list + L\n",
    "    #print (\"str2Bloat=\", str2Bloat)\n",
    "    \n",
    "    matches_Dmeta = 0\n",
    "    items_covered1 = []\n",
    "    # Find common matches based on DMETAPHONE\n",
    "    for item in str1 :\n",
    "        L = dmeta(item)\n",
    "        L = list(filter(None.__ne__, L))\n",
    "        \n",
    "        # Exact match count, using DMeta codes\n",
    "        if (len(set(str2_dmeta_list) & set(L))) > 0 : \n",
    "            matches_Dmeta += 1 \n",
    "            items_covered1.append(item)\n",
    "    if debugYesGlobal: print (\"Exact DMeta Matches (case?) : \", matches_Dmeta)\n",
    "    \n",
    "    items_covered2 = []\n",
    "    for item in str2 :\n",
    "        L = dmeta(item)\n",
    "        L = list(filter(None.__ne__, L))\n",
    "        \n",
    "        # Exact match count, using DMeta codes\n",
    "        if (len(set(str1_dmeta_list) & set(L))) > 0 : \n",
    "            #matches_Dmeta += 1 \n",
    "            items_covered2.append(item)    \n",
    "    \n",
    "    \n",
    "    if debugYesGlobal:\n",
    "        print (\"DMETA items_covered1 : \", items_covered1)\n",
    "        print (\"DMETA items_covered2 : \", items_covered2)\n",
    "    \n",
    "    #Remove items covered from both strings\n",
    "    if debugYesGlobal: print (\"BEFORE REMOVING COMMON (DMETA) >>>>1:\", ' '.join(str1), \"| 2:\", ' '.join(str2))\n",
    "    #removing ones matched with DMETA\n",
    "    for i in str1[:]:\n",
    "      if i in items_covered1:\n",
    "          str1.remove(i)\n",
    "        \n",
    "    for i in str2[:]:\n",
    "      if i in items_covered2:\n",
    "          str2.remove(i)\n",
    "    if debugYesGlobal: print (\"AFTER REMOVING COMMON (DMETA) >>>>1:\", ' '.join(str1), \"| 2:\", ' '.join(str2))\n",
    "    \n",
    "    # Edit distance with the remaining:\n",
    "    str1_for_editDist = ' '.join(str1)\n",
    "    str2_for_editDist = ' '.join(str2)\n",
    "    if debugYesGlobal: print (\"\\nstr_for_editDist1:\", str1_for_editDist, \"| str_for_editDist2:\", str2_for_editDist)\n",
    "    matches_Edit = getEditDistance (str1_for_editDist, str2_for_editDist, 2)\n",
    "        \n",
    "    total_matches = matches_exact + matches_Dmeta + matches_Edit\n",
    "    \n",
    "    if debugYesGlobal: print (\"Exact Count:\", matches_exact, \"| Dmeta Count:\", matches_Dmeta, \"| Levenshtein Count/Score:\", matches_Edit)\n",
    "    score = total_matches / (initial_count_both_strings - total_matches)\n",
    "    #print(getEditDistance (\" \", \" \", 2))\n",
    "    \n",
    "    return round(score,2)\n",
    "\n",
    "\n",
    "#print(getPhoeneticDistanceDMeta('Michael likes to eat at McDonalds',' Jackson likes to eat at McDonalds Michael'))\n",
    "#print(getPhoeneticDistanceDMeta('Michael likes to eat at McDonalds',' Jackson likes to eat at McDonalds Michael'))\n",
    "\n",
    "print(getCombinedDistanceSequential('Schmidt  Jackson McDonalds sauchages bun',' Smith Jackson McDonalds omlet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1 = 'Mikhail Jackson likes to eat is are at McDonalds'\n",
    "#string2 = 'Michael Jackson likes to eat at McDonalds'\n",
    "string2 = 'Michael likes to eat at McDonalds'\n",
    "getCombinedDistanceSequential (string1, string2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics = True\n",
    "\n",
    "# Combined Overlap Algorithm (levenshtein + metaphone)\n",
    "def getCombinedDistanceExperimental (str1, str2) :\n",
    "    \n",
    "    str1 = getStopwordRemovedString(str1)\n",
    "    str2 = getStopwordRemovedString(str2)\n",
    "    #print (str1)\n",
    "    #print (str2)\n",
    "     \n",
    "    metrics = []\n",
    "    scores = []\n",
    "    \n",
    "    metrics.append(\"Soundex\")\n",
    "    scores.append (getPhoeneticDistanceSoundex(str1, str2))\n",
    "    \n",
    "    \n",
    "    metrics.append(\"Nysiis\")\n",
    "    scores.append (getPhoeneticDistanceNysiis(str1, str2))\n",
    "\n",
    "    metrics.append(\"Metaphone\")\n",
    "    scores.append (getPhoeneticDistanceMeta(str1, str2))\n",
    "    metrics.append(\"DMetaphone\")\n",
    "    scores.append (getPhoeneticDistanceDMeta2(str1, str2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### RIP :  BAD IDEA ### Get Levenshtein based score based on 'POS's other than nouns'\n",
    "        \n",
    "    # Get Levenshtein based overlap score with 'full string'\n",
    "    #levenshteinScore = getEditDistance (str1, str2, 2)\n",
    "    metrics.append(\"Leveshtein\")\n",
    "    scores.append (getEditDistance (str1, str2, 2))\n",
    "    \n",
    "    #metrics.append(\"Sequential(Exact>Dmeta>Levenshtein)\")\n",
    "    metrics.append(\"Combined(Exact>Dmeta>Levenshtein)\")\n",
    "    scores.append (getCombinedDistanceSequential(str1, str2))    \n",
    "    \n",
    "    \n",
    "    if show_metrics : print (metrics)\n",
    "    if debugYesGlobal: \n",
    "        print (\"\\n\")\n",
    "        print (metrics)\n",
    "        print (scores)\n",
    "    return scores #max(scores)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Soundex', 'Nysiis', 'Metaphone', 'DMetaphone', 'Leveshtein', 'Combined(Exact>Dmeta>Levenshtein)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8, 0.8, 0.5, 0.8, 0.81, 0.8]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1 = 'Mikhail Jackson likes to eat is are at McDonalds'\n",
    "#string2 = 'Michael Jackson likes to eat at McDonalds'\n",
    "string2 = 'Michael likes to eat at McDonalds'\n",
    "getCombinedDistanceExperimental (string1, string2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Soundex', 'Nysiis', 'Metaphone', 'DMetaphone', 'Leveshtein', 'Combined(Exact>Dmeta>Levenshtein)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.36, 0.05]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1 = 'Sachin Tendulkar drives a bike'\n",
    "#string2 = 'Michael Jackson likes to eat at McDonalds'\n",
    "string2 = 'Michael likes to eat at McDonalds'\n",
    "getCombinedDistanceExperimental (string1, string2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Soundex', 'Nysiis', 'Metaphone', 'DMetaphone', 'Leveshtein', 'Combined(Exact>Dmeta>Levenshtein)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0, 0.0, 0.0, 0.0, 0.75, 0.6]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getCombinedDistanceExperimental ('nike', 'nikx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv ('Data_Sample_Overlap_scorer_v1_clean.csv',  encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display (df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take each row fro df and calculate all 6 Overlap scores\n",
    "for index, row in df.iterrows():\n",
    "    #print(row['system_description_3'], row['system_description_4'])\n",
    "    #['Soundex', 'Nysiis', 'Metaphone', 'DMetaphone', 'Leveshtein', 'Combined(Exact>Dmeta>Levenshtein)']\n",
    "    #[1.0, 0.0, 0.0, 0.0, 0.75, 0.6]\n",
    "    scores_row = getCombinedDistanceExperimental (row['system_description_3'], row['system_description_4'])\n",
    "        \n",
    "    df.loc[index,'Metaphone']= scores_row[2]\n",
    "    df.loc[index,'DMetaphone']= scores_row[3]\n",
    "    df.loc[index,'Combined']= scores_row[5]\n",
    "    \n",
    "display (df.head()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransformScoresToClasses (score):\n",
    "    # Keep it between a and b\n",
    "    a = -2\n",
    "    b = 3\n",
    "    \n",
    "    xmin = 0\n",
    "    xmax = 1\n",
    "    return int(round(a + (b-a) * (score - xmin)/ (xmax-xmin)))\n",
    "print(TransformScoresToClasses (0.87))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AnalyzeScores ():\n",
    "    # Take each row fro df and calculate all 6 Overlap scores\n",
    "    for index, row in df.iterrows():\n",
    "        #print(row['system_description_3'], row['system_description_4'])\n",
    "        #['Soundex', 'Nysiis', 'Metaphone', 'DMetaphone', 'Leveshtein', 'Combined(Exact>Dmeta>Levenshtein)']\n",
    "        #[1.0, 0.0, 0.0, 0.0, 0.75, 0.6]\n",
    "        scores_row = getCombinedDistanceExperimental (row['system_description_3'], row['system_description_4'])\n",
    "        scores_row = list(map(TransformScoresToClasses, scores_row))\n",
    "\n",
    "        df.loc[index,\"Soundex\"] = scores_row[0]\n",
    "        df.loc[index,'Nysiis'] = scores_row[1]\n",
    "        df.loc[index,'Metaphone']= scores_row[2]\n",
    "        df.loc[index,'DMetaphone']= scores_row[3]\n",
    "        df.loc[index,'Leveshtein']= scores_row[4] - 2 # [-1 if a,b = 1,4 | -2 if a,b = 1,5 | -1.5 if a,b = -2,-3]\n",
    "        df.loc[index,'Combined']= scores_row[5]\n",
    "\n",
    "    df['Average']= (df['Leveshtein'] + df['DMetaphone']) / 2\n",
    "\n",
    "\n",
    "\n",
    "    #df.iloc[0:5, 5:8] # first 5 rows and 5th, 6th, 7th columns of dataframe \n",
    "    #display (df.head())\n",
    "    \n",
    "    # \"Soundex\",\"Nysiis\",\"Metaphone\",\"DMetaphone\",\"Leveshtein\", \"Average\", \"Combined\"\n",
    "    n1 = 10\n",
    "    n2 = 50\n",
    "    df2 = df[n1:n2] #df.head(n)\n",
    "\n",
    "    df2.reset_index().plot(x='index', y=[\"DMetaphone\",\"Leveshtein\"], figsize=(20,5), alpha=0.7, linestyle='-', linewidth=3, xticks=range(n1, n2)).legend(title='Scores', bbox_to_anchor=(1, 1))\n",
    "    df2.reset_index().plot(x='index', y=[\"DMetaphone\", \"Combined\"], figsize=(20,5), alpha=0.7, linestyle='-', linewidth=3, xticks=range(n1, n2)).legend(title='Scores', bbox_to_anchor=(1, 1))\n",
    "\n",
    "AnalyzeScores ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 1 : Note that Levenshtein Based Overlap Score follows same pattern as Phonetic Overlap Score (Double Metaphone based). So, both cannot be kept (one should be removed). Levenshtein based overlap score is heavily truncated(dull). A good explanation being, potential Phonetic match is treated wrongly and prematurely as a spelling error. Sharp peaks and troughs indicate that Phonetic Score (Double Metaphone based) is less restrictive, comapared to Levenshtein. This is also cross-verified with real scenarios and Double Metaphone Documentation. So, if we have to keep any one, we will choose Phonetic Score (Double Metaphone). But still it misses true spelling errors. This is where Combined Overlap Score shines (Figure 2). \n",
    "#### Figure 2 : The Combined Overlap Score strikes a good balance by honouring the fine difference between Phonetic spelling variations and pure non-Phonetic spelling variations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
